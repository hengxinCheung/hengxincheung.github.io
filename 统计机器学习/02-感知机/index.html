<!-- build time:Tue Jul 07 2020 22:24:35 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta name="renderer" content="webkit"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="theme-color" content="#000000"><meta http-equiv="window-target" content="_top"><title>02-感知机 | hengxincheung&#39;s Blog</title><meta name="description" content="感知机（perceptron）是一个二分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 +1 和 -1 二值。感知机对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面。为此，倒入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。感知机模型假设输入空间（特征空间）是 $X \subset"><meta property="og:type" content="article"><meta property="og:title" content="02-感知机"><meta property="og:url" content="https://hengxincheung.github.io/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%84%9F%E7%9F%A5%E6%9C%BA/"><meta property="og:site_name" content="hengxincheung&#39;s blog"><meta property="og:description" content="感知机（perceptron）是一个二分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 +1 和 -1 二值。感知机对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面。为此，倒入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。感知机模型假设输入空间（特征空间）是 $X \subset"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/hengxinCheung/ImageBed/master/images/20200705174302.png"><meta property="article:published_time" content="2020-07-07T14:17:50.000Z"><meta property="article:modified_time" content="2020-07-07T14:18:53.609Z"><meta property="article:author" content="hengxincheung"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://raw.githubusercontent.com/hengxinCheung/ImageBed/master/images/20200705174302.png"><link rel="canonical" href="https://hengxincheung.github.io/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%84%9F%E7%9F%A5%E6%9C%BA/index.html"><link rel="alternate" href="/atom.xml" title="hengxincheung&#39;s blog" type="application/atom+xml"><link rel="icon" href="/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link href="//cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" rel="stylesheet"><link href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.css" rel="stylesheet"><meta name="generator" content="Hexo 4.2.1"></head><body class="main-center" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="slimContent"><div class="navbar-header"><div class="profile-block text-center"><a id="avatar" href="https://github.com/hengxincheung" target="_blank"><img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200"></a><h2 id="name" class="hidden-xs hidden-sm">hengxincheung</h2><h3 id="title" class="hidden-xs hidden-sm hidden-md">码农</h3><small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Guangzhou, China</small></div><div class="search" id="search-form-wrap"><form class="search-form sidebar-form"><div class="input-group"><input type="text" class="search-form-input form-control" placeholder="搜索"> <span class="input-group-btn"><button type="submit" class="search-form-submit btn btn-flat" onclick="return!1"><i class="icon icon-search"></i></button></span></div></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech> <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div></div><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button></div><nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation"><ul class="nav navbar-nav main-nav menu-highlight"><li class="menu-item menu-item-home"><a href="/."><i class="icon icon-home-fill"></i> <span class="menu-title">首页</span></a></li><li class="menu-item menu-item-archives"><a href="/archives"><i class="icon icon-archives-fill"></i> <span class="menu-title">归档</span></a></li><li class="menu-item menu-item-categories"><a href="/categories"><i class="icon icon-folder"></i> <span class="menu-title">分类</span></a></li><li class="menu-item menu-item-tags"><a href="/tags"><i class="icon icon-tags"></i> <span class="menu-title">标签</span></a></li><li class="menu-item menu-item-about"><a href="/about"><i class="icon icon-cup-fill"></i> <span class="menu-title">关于</span></a></li></ul><ul class="social-links"><li><a href="https://github.com/hengxincheung" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li><li><a href="/null" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top"><i class="icon icon-weibo"></i></a></li><li><a href="/null" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top"><i class="icon icon-twitter"></i></a></li><li><a href="/null" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul></nav></div></header><aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><div class="widget"><h3 class="widget-title">公告</h3><div class="widget-body"><div id="board"><div class="content"><p>欢迎您，瓜子和茶都没有。</p></div></div></div></div><div class="widget"><h3 class="widget-title">分类</h3><div class="widget-body"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Java%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/">Java编程思想</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/">linux快速入门</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/numpy%E6%95%99%E7%A8%8B/">numpy教程</a><span class="category-list-count">15</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">统计机器学习</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a><span class="category-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签云</h3><div class="widget-body tagcloud"><a href="/tags/Java/" style="font-size:14px">Java</a> <a href="/tags/RESTful/" style="font-size:13px">RESTful</a> <a href="/tags/git/" style="font-size:13px">git</a> <a href="/tags/linux/" style="font-size:13.5px">linux</a> <a href="/tags/numpy/" style="font-size:13.75px">numpy</a> <a href="/tags/python/" style="font-size:13.75px">python</a> <a href="/tags/web/" style="font-size:13.25px">web</a> <a href="/tags/%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F/" style="font-size:13px">权限系统</a> <a href="/tags/%E7%94%A8%E6%88%B7%E7%B3%BB%E7%BB%9F/" style="font-size:13px">用户系统</a> <a href="/tags/%E7%99%BB%E5%BD%95/" style="font-size:13px">登录</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size:13px">统计机器学习</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/" style="font-size:14px">编程思想</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size:13px">设计模式</a> <a href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/" style="font-size:13px">随机森林</a></div></div><div class="widget"><h3 class="widget-title">最新文章</h3><div class="widget-body"><ul class="recent-post-list list-unstyled no-thumbnail"><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">统计机器学习</a></p><p class="item-title"><a href="/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-k%E8%BF%91%E9%82%BB%E6%B3%95/" class="title">03-k近邻法</a></p><p class="item-date"><time datetime="2020-07-07T14:18:36.000Z" itemprop="datePublished">2020-07-07</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">统计机器学习</a></p><p class="item-title"><a href="/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="title">02-感知机</a></p><p class="item-date"><time datetime="2020-07-07T14:17:50.000Z" itemprop="datePublished">2020-07-07</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">统计机器学习</a></p><p class="item-title"><a href="/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/" class="title">01-统计学习方法概论</a></p><p class="item-date"><time datetime="2020-07-05T14:20:01.000Z" itemprop="datePublished">2020-07-05</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/Java%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/">Java编程思想</a></p><p class="item-title"><a href="/Java%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/21-%E5%B9%B6%E5%8F%91/" class="title">21-并发</a></p><p class="item-date"><time datetime="2020-07-03T13:31:04.000Z" itemprop="datePublished">2020-07-03</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/Java%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/">Java编程思想</a></p><p class="item-title"><a href="/Java%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/20-%E6%B3%A8%E8%A7%A3/" class="title">20-注解</a></p><p class="item-date"><time datetime="2020-07-03T13:30:32.000Z" itemprop="datePublished">2020-07-03</time></p></div></li></ul></div></div></div></aside><aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><nav id="toc" class="article-toc"><h3 class="toc-title">文章目录</h3><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机模型"><span class="toc-number">1.</span> <span class="toc-text">感知机模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机学习策略"><span class="toc-number">2.</span> <span class="toc-text">感知机学习策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据集的线性可分性"><span class="toc-number">2.1.</span> <span class="toc-text">数据集的线性可分性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#感知机学习策略-1"><span class="toc-number">2.2.</span> <span class="toc-text">感知机学习策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#感知机学习算法"><span class="toc-number">3.</span> <span class="toc-text">感知机学习算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#感知机学习算法的原始形式"><span class="toc-number">3.1.</span> <span class="toc-text">感知机学习算法的原始形式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算法的收敛性"><span class="toc-number">3.2.</span> <span class="toc-text">算法的收敛性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#感知机学习算法的对偶形式"><span class="toc-number">3.3.</span> <span class="toc-text">感知机学习算法的对偶形式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码实现"><span class="toc-number">4.</span> <span class="toc-text">代码实现</span></a></li></ol></nav></div></aside><main class="main" role="main"><div class="content"><article id="post-统计机器学习/02-感知机" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting"><div class="article-header"><h1 class="article-title" itemprop="name">02-感知机</h1><div class="article-meta"><span class="article-date"><i class="icon icon-calendar-check"></i> <a href="/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="article-date"><time datetime="2020-07-07T14:17:50.000Z" itemprop="datePublished">2020-07-07</time></a></span> <span class="article-category"><i class="icon icon-folder"></i> <a class="article-category-link" href="/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">统计机器学习</a></span> <span class="article-read hidden-xs"><i class="icon icon-eye-fill" aria-hidden="true"></i> <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span></span></span> <span class="post-comment"><i class="icon icon-comment"></i> <a href="/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%84%9F%E7%9F%A5%E6%9C%BA/#comments" class="article-comment-link">评论</a></span> <span class="post-wordcount hidden-xs" itemprop="wordCount">字数统计: 2k(字)</span> <span class="post-readcount hidden-xs" itemprop="timeRequired">阅读时长: 7(分)</span></div></div><div class="article-entry marked-body" itemprop="articleBody"><p>感知机（perceptron）是一个二分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 +1 和 -1 二值。感知机对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面。为此，倒入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。</p><h2 id="感知机模型"><a href="#感知机模型" class="headerlink" title="感知机模型"></a>感知机模型</h2><p>假设输入空间（特征空间）是 $X \subseteq R^n$，输出空间是 $Y = {+1, -1}$。由输入空间到输出空间的如下函数称为感知机：</p><script type="math/tex;mode=display">f(x) = sign(w \cdot x + b)</script><p>其中，$w$ 和 $b$ 为感知机模型参数。$w$ 叫做权值（weight）或权值向量（weight vecotr)，$b$ 叫做偏置（bias）。$w \cdot x$ 表示 $w$ 和 $x$ 的内积，$sign$ 是符号函数，即：</p><script type="math/tex;mode=display">sign(x)=\begin{cases}
1, &x \ge 0 \\
0, &x \lt 0 \\
\end{cases}</script><p>感知机是一种线性分类模型，属于判别模型。感知机模型的假设空间是定义在特征空间中的所有线性分类模型（linear classification model）或线性分类器（linear classifier），即函数集合 $\{f | f(x)=w \cdot x + b\}$。</p><p>感知机有如下几何解释：线性方程</p><script type="math/tex;mode=display">w \cdot x + b = 0</script><p>对应于特征空间 $R^n$ 中的一个超平面 $S$，其中 $w$ 是超平面的法向量，$b$ 是超平面的截距。这个超平面将特征空间划分为两个部分，位于两部分的点（特征向量）分别被分为正、负两类。因此，超平面 $S$ 也被称为分离超平面（separating hyperplane）。</p><p><img src="https://raw.githubusercontent.com/hengxinCheung/ImageBed/master/images/20200705174302.png" alt="感知机模型"></p><h2 id="感知机学习策略"><a href="#感知机学习策略" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h2><h3 id="数据集的线性可分性"><a href="#数据集的线性可分性" class="headerlink" title="数据集的线性可分性"></a>数据集的线性可分性</h3><p>给定一个数据集，如果存在某个超平面 $S$：</p><script type="math/tex;mode=display">w \cdot x + b = 0</script><p>能够将数据集正实例点和负实例点完全正确地划分到超平面的两侧，即对所有 $y_i = +1$ 的实例 $i$,有 $w \cdot x_i + b &gt; 0$；对有$y_i = -1$ 的实例 $i$,有 $w \cdot x_i + b &lt; 0$。则称数据集为线性可分数据集（linearly separable data set）；否则，称数据集线性不可分。</p><h3 id="感知机学习策略-1"><a href="#感知机学习策略-1" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h3><p>假设训练数据集是线性可分的，感知机学习的目标是求得一个能够将训练集正实例点和负实例点完全正确分开的分离超平面。为了找出这样的超平面，即确定感知机模型参数 $w$,$b$，需要确定一个学习策略，即定义（经验）损失函数并将损失函数极小化。</p><p>损失函数的一个自然选择是误分类点的总数。但是，这样的损失函数不是参数 $w$,$b$ 的连续可导函数，不易优化。损失函数的另一个选择是误分类点到超平面 $S$ 的总距离，这是感知机锁采用的。为此，首先写出输入空间任一点到超平面的距离：</p><script type="math/tex;mode=display">\frac{1}{\vert\vert w \vert\vert} \vert w \cdot x_0 + b \vert</script><p>这里的 $\vert\vert w \vert\vert$ 是 $w$ 的 $L_2$ 范数。</p><p>其次，对于误分类的数据 $(x_i,y_i)$ 来说，</p><script type="math/tex;mode=display">-y_i (w \cdot x_i + b) > 0</script><p>成立。因为当 $w \cdot x_i + b &gt; 0$ 时，$y_i = -1$，而当 $w \cdot x_i + b &lt; 0$ 时，$y_i = +1$。因此，误分类点 $x_i$ 到超平面 $S$ 的距离是：</p><script type="math/tex;mode=display">-\frac{1}{\vert\vert w \vert\vert} \sum_{x_i \in M} y_i(w \cdot x + b)</script><p>不考虑 $\vert\vert w \vert\vert$，就得到感知机学习的损失函数。</p><p>感知机 $sign(w \cdot x + b)$ 学习的损失函数定义为：</p><script type="math/tex;mode=display">L(w, b) = -\sum_{x_i \in M} y_i(w \cdot x_i + b)</script><p>其中 $M$ 为误分类点的集合。这个损失函数就是感知机学习的经验风险函数。</p><p>显然，损失函数 $L(w, b)$ 是非负的。如果没有误分类点，损失函数值是0。而且，误分类点越少，误分类点离超平面越近，损失函数值就越小。</p><h2 id="感知机学习算法"><a href="#感知机学习算法" class="headerlink" title="感知机学习算法"></a>感知机学习算法</h2><p>感知机学习问题转化为求解损失函数的最优化问题，最优化的方法是随机梯度下降法。</p><h3 id="感知机学习算法的原始形式"><a href="#感知机学习算法的原始形式" class="headerlink" title="感知机学习算法的原始形式"></a>感知机学习算法的原始形式</h3><p>求解参数 $w$,$b$，使其为以下损失函数极小化问题的解：</p><script type="math/tex;mode=display">\underset{w,b}{min} L(w, b) = -\sum_{x_i \in M} y_i (w \cdot x_i + b)</script><p>感知机学习算法是误分类驱动的，具体采用随机梯度下降法（stochastic gradient descent）。首先，任意选取一个超平面 $w_0$,$b_0$，然后用梯度下降法不断地极小化目标函数。极小化过程中不是一次使 $M$ 中所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降。</p><p>假设误分类点集合 $M$ 是固定的，那么损失函数 $L(w, b)$ 的梯度由下面的公式给出：</p><script type="math/tex;mode=display">\nabla_{w} L(w, b) = -\sum_{x_i \in M}y_ix_i</script><script type="math/tex;mode=display">\nabla_{b} L(w, b) = -\sum_{x_i \in M}y_ix_i</script><p>随机选取一个误分类点 $(x_i, y_i)$，对 $w$,$b$ 进行更新：</p><script type="math/tex;mode=display">w \leftarrow w + \eta y_i x_i</script><script type="math/tex;mode=display">b \leftarrow b + \eta y_i</script><p>$\eta (0 \lt \eta \leq 1)$ 是步长，在统计学习中又称为学习率（learning rate）。这样，通过迭代可以期待损失函数 $L(w,b)$ 不断减小，直到为0。</p><p><strong>感知机学习算法的原始形式：</strong></p><p>输入：训练数据集 $T = \{ (x_1,y_1),(x_2,y_2),…,(x_N,y_N) \}$；学习率 $\eta (0 \lt \eta \leq 1)$。</p><p>输出：$w,b$；感知机模型 $f(x)=sign(w \cdot x + b)$</p><ul><li>选取初始值 $w_0,b_0$</li><li>在训练集中选取数据 $(x_i, y_i)$</li><li>如果 $y_i(w \cdot x_i + b) \leq 0$:<script type="math/tex">w \leftarrow w + \eta y_i x_i \\ b \leftarrow b + \eta y_i</script></li><li>转至第二步，直至训练集中没有误分类点</li></ul><p>注意：感知机学习算法由于采用不同的初值或选取不同的误分类点，解可以不同。</p><h3 id="算法的收敛性"><a href="#算法的收敛性" class="headerlink" title="算法的收敛性"></a>算法的收敛性</h3><p>对于线性可分数据集，感知机学习算法原始形式收敛，即经过有限次迭代可以得到一个将训练集完全正确划分的分离超平面及感知机模型。</p><h3 id="感知机学习算法的对偶形式"><a href="#感知机学习算法的对偶形式" class="headerlink" title="感知机学习算法的对偶形式"></a>感知机学习算法的对偶形式</h3><p>对偶形式的基本想法是，将 $w$ 和 $b$ 表示为实例 $x_i$ 和标记 $y_i$ 的线性组合的形式，通过求解其系数而求得 $w$ 和 $b$。不失一般性，可假设初始值 $w_0,b_0$ 均为0.对于误分类点 $(x_i, y_i)$ 通过</p><script type="math/tex;mode=display">w \leftarrow w + \eta y_i x_i</script><script type="math/tex;mode=display">b \leftarrow b + \eta y_i</script><p>逐步修改 $w,b$，设修改 $n$ 此，则 $w,b$ 关于 $(x_i, y_i)$ 的增量分别是 $\alpha_i y_i x_i$ 和 $\alpha_i y_i$，这里 $\alpha_i = n_i \eta$。这样，从学习过程不难看出，最后学习到的 $w,b$ 可分别表示为：</p><script type="math/tex;mode=display">w = \sum_{i=1}^{N}\alpha_i y_i x_i</script><script type="math/tex;mode=display">b = \sum_{i=1}^{N}\alpha_i y_i</script><p>实例点更新次数越多，意味着它距离分离超平面越近，也就越难正确分离。换句话说，这样的实例对学习结果影响最大。</p><p><strong>感知机学习算法的对偶形式：</strong></p><p>输入：训练数据集 $T = \{ (x_1,y_1),(x_2,y_2),…,(x_N,y_N) \}$；学习率 $\eta (0 \lt \eta \leq 1)$。</p><p>输出：$\alpha, b$；感知机模型 $f(x)=sign(\sum_{j=1}^{N} \alpha_j y_j x_j \cdot x + b)$</p><p>其中 $\alpha = (\alpha_1, \alpha_2,…,\alpha_N)^{T}$</p><ul><li>$\alpha \leftarrow 0, b \leftarrow 0$</li><li>在训练集中选取数据 $(x_i, y_i)$</li><li>如果 $y_i(\sum_{j=1}^{N} \alpha_j y_j x_j \cdot x_j +b) \leq 0$，<script type="math/tex">\alpha_i \leftarrow \alpha_i + \eta \\ b \leftarrow b + \eta y_i</script></li><li>转至第二步直到没有误分类数据。</li></ul><p>对偶形式中训练实例仅以内积的形式出现。为了方便，可以预先将训练集中实例键的内积计算出来并以矩阵的形式存储，这个矩阵就是所有的Gram矩阵：</p><script type="math/tex;mode=display">G = [x_i \cdot x_j]_{N \times N}</script><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p><a href="https://github.com/hengxinCheung/StatisticalLearning/blob/master/perceptron/perceptron.py" target="_blank" rel="noopener">感知机代码实现</a></p></div><div class="article-footer"><blockquote class="mt-2x"><ul class="post-copyright list-unstyled"><li class="post-copyright-link hidden-xs"><strong>本文链接：</strong> <a href="https://hengxincheung.github.io/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%84%9F%E7%9F%A5%E6%9C%BA/" title="02-感知机" target="_blank" rel="external">https://hengxincheung.github.io/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%84%9F%E7%9F%A5%E6%9C%BA/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！</li></ul></blockquote><div class="panel panel-default panel-badger"><div class="panel-body"><figure class="media"><div class="media-left"><a href="https://github.com/hengxincheung" target="_blank" class="img-burn thumb-sm visible-lg"><img src="/images/avatar.jpg" class="img-rounded w-full" alt=""></a></div><div class="media-body"><h3 class="media-heading"><a href="https://github.com/hengxincheung" target="_blank"><span class="text-dark">hengxincheung</span><small class="ml-1x">码农</small></a></h3><div>Encode my life, Decode the future</div></div></figure></div></div></div></article><section id="comments"><div id="vcomments"></div></section></div><nav class="bar bar-footer clearfix" data-stick-bottom><div class="bar-inner"><ul class="pager pull-left"><li class="prev"><a href="/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-k%E8%BF%91%E9%82%BB%E6%B3%95/" title="03-k近邻法"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a></li><li class="next"><a href="/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/" title="01-统计学习方法概论"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a></li><li class="toggle-toc"><a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button"><span>[&nbsp;</span><span>文章目录</span> <i class="text-collapsed icon icon-anchor"></i> <i class="text-in icon icon-close"></i> <span>]</span></a></li></ul><button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button><div class="bar-right"><div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div></div></div></nav><div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog"><div class="modal-dialog" role="document"><div class="modal-content donate"><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button><div class="modal-body"><div class="donate-box"><div class="donate-head"><p>感谢您的支持，我会继续努力的!</p></div><div class="tab-content"><div role="tabpanel" class="tab-pane fade active in" id="alipay"><div class="donate-payimg"><img src="/images/donate/alipay.jpg" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p></div><div role="tabpanel" class="tab-pane fade" id="wechatpay"><div class="donate-payimg"><img src="/images/donate/wechatpay.jpg" alt="扫码支持" title="扫一扫"></div><p class="text-muted mv">扫码打赏，你说多少就多少</p><p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p></div></div><div class="donate-footer"><ul class="nav nav-tabs nav-justified" role="tablist"><li role="presentation" class="active"><a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a></li><li role="presentation"><a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a></li></ul></div></div></div></div></div></div></main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter"><ul class="social-links"><li><a href="https://github.com/hengxincheung" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li><li><a href="/null" target="_blank" title="Weibo" data-toggle="tooltip" data-placement="top"><i class="icon icon-weibo"></i></a></li><li><a href="/null" target="_blank" title="Twitter" data-toggle="tooltip" data-placement="top"><i class="icon icon-twitter"></i></a></li><li><a href="/null" target="_blank" title="Behance" data-toggle="tooltip" data-placement="top"><i class="icon icon-behance"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul><div class="copyright"><div class="publishby"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span></div></div></footer><script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script><script>window.jQuery||document.write('<script src="js/jquery.min.js"><\/script>')</script><script src="/js/plugin.min.js"></script><script src="/js/application.js"></script><script>!function(T){var N={TRANSLATION:{POSTS:"文章",PAGES:"页面",CATEGORIES:"分类",TAGS:"标签",UNTITLED:"(未命名)"},ROOT_URL:"/",CONTENT_URL:"/content.json"};T.INSIGHT_CONFIG=N}(window)</script><script src="/js/insight.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/npm/valine"></script><script type="text/javascript">var GUEST=["nick","mail","link"],meta="nick,mail,link";meta=meta.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#vcomments",verify:!1,notify:!1,appId:"",appKey:"",placeholder:"Just go go",avatar:"mm",meta:meta,pageSize:"10",visitor:!1})</script><script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.3.5/dist/jquery.fancybox.min.js"></script><script>$(document).ready(function(){$("article img").not("[hidden]").not(".panel-body img").each(function(){var a=$(this),t=a.attr("alt"),n=a.parent("a");if(n.length<1){var e=this.getAttribute("src"),r=e.lastIndexOf("?");-1!=r&&(e=e.substring(0,r)),n=a.wrap('<a href="'+e+'"></a>').parent("a")}n.attr("data-fancybox","images"),t&&n.attr("data-caption",t)}),$().fancybox({selector:'[data-fancybox="images"]',hash:!1,loop:!1})})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html><!-- rebuild by neat -->